## Generative AI

Generative AI is a type of artificial intelligence that can **create new content** such as text, images, music, or code by learning patterns from existing data.

### Examples
- **ChatGPT** – generates human-like text.
- **DALL·E** – generates images from text.
- **GitHub Copilot** – suggests and generates code.

### Insight
Traditional AI focuses on tasks like classification and prediction. Generative AI is different—it **creates** new data, which opens up creative and automation possibilities.

---

## Types of Generative Models

### Examples
- **GPT (Generative Pretrained Transformer)** – Text generation
- **DALL·E / Stable Diffusion** – Image generation
- **StyleGAN** – Face and image generation
- **VAE (Variational Autoencoder)** – Image compression + generation
- **RNN / LSTM** – Older models for text and music generation

### Insight
Each model has its strengths:
- **Transformers** (e.g., GPT) are great for language and sequential data.
- **GANs** are excellent for generating realistic images.
- **VAEs** are used for controlled, smooth variation in generated data.

### Connection
As a dev, knowing the types helps you choose:
- Use **GPT-like models** for chatbots, code generation.
- Use **GANs/VAEs** for image-related tasks.
- Use **diffusion models** for high-quality, customizable image generation.

---

## LLMs (Large Language Models)

LLMs are deep learning models trained on massive amounts of text data to **understand and generate human-like language**. They can perform tasks like text generation, translation, summarization, and question answering.

### Examples
- **GPT (Generative Pretrained Transformer)** – Text generation, conversational AI.
- **BERT (Bidirectional Encoder Representations from Transformers)** – Text understanding, sentiment analysis.
- **T5 (Text-to-Text Transfer Transformer)** – Multi-task text generation and transformation.

