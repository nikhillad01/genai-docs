
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../intro/">
      
      
        <link rel="next" href="../prompt_engineering/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.11">
    
    
      
        <title>LLMs - GenAI Docs</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.4af4bdda.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#llms-large-language-models" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="GenAI Docs" class="md-header__button md-logo" aria-label="GenAI Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            GenAI Docs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              LLMs
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="GenAI Docs" class="md-nav__button md-logo" aria-label="GenAI Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    GenAI Docs
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" checked>
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Foundations
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Foundations
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intro/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    LLMs
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    LLMs
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#llms-large-language-models" class="md-nav__link">
    <span class="md-ellipsis">
      LLMs (Large Language Models)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vectors" class="md-nav__link">
    <span class="md-ellipsis">
      Vectors
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Vectors">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#why-we-use-vectors" class="md-nav__link">
    <span class="md-ellipsis">
      Why We Use Vectors
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-of-a-vector-representation" class="md-nav__link">
    <span class="md-ellipsis">
      Example of a Vector Representation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-vectors-are-important" class="md-nav__link">
    <span class="md-ellipsis">
      Why Vectors Are Important
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-vectors-capture-word-context" class="md-nav__link">
    <span class="md-ellipsis">
      How Vectors Capture Word Context
    </span>
  </a>
  
    <nav class="md-nav" aria-label="How Vectors Capture Word Context">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#meaning-of-vectors-in-context" class="md-nav__link">
    <span class="md-ellipsis">
      Meaning of Vectors in Context
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Meaning of Vectors in Context">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-context-is-captured" class="md-nav__link">
    <span class="md-ellipsis">
      How Context is Captured
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dimensionality-and-contextual-representation" class="md-nav__link">
    <span class="md-ellipsis">
      Dimensionality and Contextual Representation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#word-sense-disambiguation-wsd" class="md-nav__link">
    <span class="md-ellipsis">
      Word Sense Disambiguation (WSD)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-vectors-capture-context" class="md-nav__link">
    <span class="md-ellipsis">
      Why Vectors Capture Context
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tokenization-embeddings-and-transformers" class="md-nav__link">
    <span class="md-ellipsis">
      Tokenization, Embeddings, and Transformers
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tokenization, Embeddings, and Transformers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tokenization" class="md-nav__link">
    <span class="md-ellipsis">
      Tokenization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      Embeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformers" class="md-nav__link">
    <span class="md-ellipsis">
      Transformers
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../prompt_engineering/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Prompt Engineering Basics
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tools_overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tools Overview
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#llms-large-language-models" class="md-nav__link">
    <span class="md-ellipsis">
      LLMs (Large Language Models)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vectors" class="md-nav__link">
    <span class="md-ellipsis">
      Vectors
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Vectors">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#why-we-use-vectors" class="md-nav__link">
    <span class="md-ellipsis">
      Why We Use Vectors
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-of-a-vector-representation" class="md-nav__link">
    <span class="md-ellipsis">
      Example of a Vector Representation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-vectors-are-important" class="md-nav__link">
    <span class="md-ellipsis">
      Why Vectors Are Important
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-vectors-capture-word-context" class="md-nav__link">
    <span class="md-ellipsis">
      How Vectors Capture Word Context
    </span>
  </a>
  
    <nav class="md-nav" aria-label="How Vectors Capture Word Context">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#meaning-of-vectors-in-context" class="md-nav__link">
    <span class="md-ellipsis">
      Meaning of Vectors in Context
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Meaning of Vectors in Context">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-context-is-captured" class="md-nav__link">
    <span class="md-ellipsis">
      How Context is Captured
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dimensionality-and-contextual-representation" class="md-nav__link">
    <span class="md-ellipsis">
      Dimensionality and Contextual Representation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#word-sense-disambiguation-wsd" class="md-nav__link">
    <span class="md-ellipsis">
      Word Sense Disambiguation (WSD)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-vectors-capture-context" class="md-nav__link">
    <span class="md-ellipsis">
      Why Vectors Capture Context
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tokenization-embeddings-and-transformers" class="md-nav__link">
    <span class="md-ellipsis">
      Tokenization, Embeddings, and Transformers
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tokenization, Embeddings, and Transformers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tokenization" class="md-nav__link">
    <span class="md-ellipsis">
      Tokenization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      Embeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformers" class="md-nav__link">
    <span class="md-ellipsis">
      Transformers
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h2 id="llms-large-language-models">LLMs (Large Language Models)</h2>
<p>LLMs are deep learning models trained on massive amounts of text data to <strong>understand and generate human-like language</strong>. They can perform tasks like text generation, translation, summarization, and question answering.</p>
<p><strong>Examples</strong></p>
<ul>
<li><strong>GPT (Generative Pretrained Transformer)</strong> – Text generation, conversational AI.</li>
<li><strong>BERT (Bidirectional Encoder Representations from Transformers)</strong> – Text understanding, sentiment analysis.</li>
<li><strong>T5 (Text-to-Text Transfer Transformer)</strong> – Multi-task text generation and transformation.</li>
</ul>
<hr />
<h1 id="vectors">Vectors</h1>
<p>In machine learning and AI, a <strong>vector</strong> is a list (or array) of <strong>numerical values</strong>. These numbers represent a <strong>point</strong> in a multi-dimensional space.</p>
<ul>
<li>Each number in the vector is called a <strong>dimension</strong>.</li>
<li>For example, a vector could be <code>[2, 5, 3]</code>, which has 3 dimensions (x, y, and z).</li>
</ul>
<p>In the case of <strong>word embeddings</strong>, a word like "cat" is represented as a vector, where each number in the vector reflects a feature of the word, such as its meaning, context, or relationship to other words.</p>
<h2 id="why-we-use-vectors">Why We Use Vectors</h2>
<p>Vectors allow us to:</p>
<ol>
<li><strong>Numerically represent words or data</strong>: Words themselves are not numbers, but by converting them to vectors, we make them usable in mathematical models.</li>
<li><strong>Capture relationships and similarities</strong>: The distance between two vectors can show how similar two words are. For example, the vector for "king" might be close to the vector for "queen" because they share similar meanings.</li>
</ol>
<h2 id="example-of-a-vector-representation">Example of a Vector Representation</h2>
<p>A word like "apple" might be represented as a vector like <code>[0.1, 0.2, 0.3, 0.4]</code>, where:
- <code>0.1</code> might correspond to the word's <strong>fruit-related meaning</strong>.
- <code>0.2</code> could represent its <strong>sweetness</strong>.
- <code>0.3</code> might capture <strong>its association with technology</strong> (like Apple Inc.).
- <code>0.4</code> could relate to <strong>color or shape</strong>.</p>
<p>Each dimension in the vector represents a feature that helps the model understand the word better.</p>
<h2 id="why-vectors-are-important">Why Vectors Are Important</h2>
<p>Vectors allow models to:
- <strong>Process words as numbers</strong>, making it easier to apply mathematical operations (like calculating similarities or differences).
- <strong>Capture context</strong>: A vector for the word "bank" in a financial context will be different from one in a riverbank context, allowing models to handle polysemy (words with multiple meanings).</p>
<h2 id="how-vectors-capture-word-context">How Vectors Capture Word Context</h2>
<h3 id="meaning-of-vectors-in-context">Meaning of Vectors in Context</h3>
<p>When we convert words into vectors (using <strong>embeddings</strong>), each word gets a <strong>numerical representation</strong> that captures its <strong>meaning</strong> based on <strong>context</strong>. This is achieved by training the model on large amounts of text where it learns how words are used in different situations.</p>
<ul>
<li><strong>Context matters</strong>: If the word "orange" is used in a sentence like "I ate an orange," the model learns that "orange" refers to a <strong>fruit</strong>. If it’s used in "The sky is orange," the model learns that it refers to a <strong>color</strong>.</li>
</ul>
<h4 id="how-context-is-captured">How Context is Captured</h4>
<p>Embeddings are generated using techniques like <strong>Word2Vec</strong> or <strong>GloVe</strong>. These methods assign words to vectors based on their <strong>co-occurrence</strong> with other words in different contexts.</p>
<p><strong>Example 1: Word2Vec (Skip-Gram Model)</strong></p>
<ul>
<li>When the word "orange" is used in a sentence like "I ate an orange," the model will learn that "orange" often appears near words like <strong>fruit</strong>, <strong>delicious</strong>, <strong>eat</strong>.</li>
<li>When used in "The sky is orange," it will often appear near words like <strong>color</strong>, <strong>sunset</strong>, <strong>sky</strong>.</li>
</ul>
<p>The model will generate <strong>different vectors</strong> for "orange" in these contexts because of the surrounding words. These vectors will reflect the specific context of the word in each case.</p>
<p><strong>Example 2: GloVe (Global Vectors for Word Representation)</strong></p>
<ul>
<li>GloVe looks at the <strong>global context</strong> of words across an entire corpus. It learns that "orange" shares different co-occurrence statistics with words like <strong>fruit</strong> and <strong>color</strong>.</li>
<li>The resulting vectors will still be <strong>close to each other</strong>, but they’ll be distinct enough to represent different meanings in different contexts.</li>
</ul>
<h4 id="dimensionality-and-contextual-representation">Dimensionality and Contextual Representation</h4>
<p>Each vector typically has many dimensions (e.g., 300-dimensional). Each dimension doesn’t directly correspond to a specific meaning like "sweetness" or "color," but rather represents <strong>latent features</strong> learned from data. These features emerge from how words relate to other words in sentences.</p>
<p><strong>For Example:</strong>
- <strong>Context 1</strong>: "I ate an orange" – The vector might emphasize features related to <strong>edible</strong>, <strong>fruit</strong>, and <strong>taste</strong>.
- <strong>Context 2</strong>: "The sunset was orange" – The vector might emphasize features related to <strong>color</strong>, <strong>sky</strong>, and <strong>nature</strong>.</p>
<h4 id="word-sense-disambiguation-wsd">Word Sense Disambiguation (WSD)</h4>
<p>Models like <strong>BERT</strong> or <strong>GPT</strong> are designed to handle this. They consider the full sentence (or even larger context) to adjust the vector of a word dynamically. This process is called <strong>contextual embedding</strong>, where the same word might have slightly different vector representations depending on its usage.</p>
<h4 id="why-vectors-capture-context">Why Vectors Capture Context</h4>
<p>By using large corpora of text, embeddings capture the <strong>statistical relationship</strong> between words in various contexts. This allows models to differentiate meanings like:
- "Orange" as a <strong>fruit</strong> when surrounded by words like "eat," "juice," and "sweet."
- "Orange" as a <strong>color</strong> when surrounded by words like "sky," "sunset," and "bright."</p>
<p>Thus, <strong>vectors</strong> represent both the general meaning of the word and its specific meaning in context.</p>
<h1 id="tokenization-embeddings-and-transformers">Tokenization, Embeddings, and Transformers</h1>
<h2 id="tokenization">Tokenization</h2>
<p>Tokenization is the process of breaking down text into smaller pieces, such as words, subwords, or characters. These tokens are then fed into models for processing.</p>
<ul>
<li>
<p><strong>Why We Need It</strong>: Tokenization allows the model to handle text in manageable units. It’s necessary because the model needs a consistent format to understand and process varying-length input.</p>
</li>
<li>
<p><strong>Example</strong>: "I love AI" becomes <code>['I', 'love', 'AI']</code>.</p>
</li>
</ul>
<h2 id="embeddings">Embeddings</h2>
<p>Embeddings are dense vector representations of tokens. Each token is mapped to a vector of numbers that capture its meaning based on context.</p>
<ul>
<li>
<p><strong>Why We Need It</strong>: Embeddings allow words to be represented in a way that preserves their semantic meaning. Unlike traditional one-hot encoding, which only shows whether a word exists or not, embeddings capture <strong>context</strong> and <strong>relationships</strong> between words.</p>
</li>
<li>
<p><strong>Word Embedding Example</strong>: The word "cat" might be represented as <code>[0.1, 0.2, 0.3, ...]</code> in a multi-dimensional space.</p>
</li>
</ul>
<h2 id="transformers">Transformers</h2>
<p>Transformers are a type of neural network architecture that processes input data in <strong>parallel</strong> rather than sequentially, making them highly efficient. They use <strong>self-attention mechanisms</strong> to focus on different parts of the input sequence for better context understanding.</p>
<ul>
<li>
<p><strong>Why We Need It</strong>: 
Transformers are crucial because they handle long-range dependencies in text and process data much faster than older models like RNNs. <strong>Self-attention</strong> helps the model focus on relevant parts of the input sequence, even if they are far apart in the text.</p>
</li>
<li>
<p><strong>Key Concepts</strong>:</p>
<ul>
<li><strong>Self-Attention</strong>: Allows the model to consider all parts of the input sequence at once, making it more efficient for tasks requiring context from multiple parts of the text.</li>
<li><strong>Positional Encoding</strong>: Adds information about the order of tokens, ensuring the model understands the sequence of the input.</li>
</ul>
</li>
<li>
<p><strong>Popular Transformers</strong>:</p>
<ul>
<li><strong>GPT</strong>: Focuses on autoregressive text generation.</li>
<li><strong>BERT</strong>: Focuses on bidirectional context understanding.</li>
</ul>
</li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
    
  </body>
</html>