{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"foundations/LLMs/","title":"LLMs","text":""},{"location":"foundations/LLMs/#llms-large-language-models","title":"LLMs (Large Language Models)","text":"<p>LLMs are deep learning models trained on massive amounts of text data to understand and generate human-like language. They can perform tasks like text generation, translation, summarization, and question answering.</p> <p>Examples</p> <ul> <li>GPT (Generative Pretrained Transformer) \u2013 Text generation, conversational AI.</li> <li>BERT (Bidirectional Encoder Representations from Transformers) \u2013 Text understanding, sentiment analysis.</li> <li>T5 (Text-to-Text Transfer Transformer) \u2013 Multi-task text generation and transformation.</li> </ul>"},{"location":"foundations/LLMs/#vectors","title":"Vectors","text":"<p>In machine learning and AI, a vector is a list (or array) of numerical values. These numbers represent a point in a multi-dimensional space.</p> <ul> <li>Each number in the vector is called a dimension.</li> <li>For example, a vector could be <code>[2, 5, 3]</code>, which has 3 dimensions (x, y, and z).</li> </ul> <p>In the case of word embeddings, a word like \"cat\" is represented as a vector, where each number in the vector reflects a feature of the word, such as its meaning, context, or relationship to other words.</p>"},{"location":"foundations/LLMs/#why-we-use-vectors","title":"Why We Use Vectors","text":"<p>Vectors allow us to:</p> <ol> <li>Numerically represent words or data: Words themselves are not numbers, but by converting them to vectors, we make them usable in mathematical models.</li> <li>Capture relationships and similarities: The distance between two vectors can show how similar two words are. For example, the vector for \"king\" might be close to the vector for \"queen\" because they share similar meanings.</li> </ol>"},{"location":"foundations/LLMs/#example-of-a-vector-representation","title":"Example of a Vector Representation","text":"<p>A word like \"apple\" might be represented as a vector like <code>[0.1, 0.2, 0.3, 0.4]</code>, where: - <code>0.1</code> might correspond to the word's fruit-related meaning. - <code>0.2</code> could represent its sweetness. - <code>0.3</code> might capture its association with technology (like Apple Inc.). - <code>0.4</code> could relate to color or shape.</p> <p>Each dimension in the vector represents a feature that helps the model understand the word better.</p>"},{"location":"foundations/LLMs/#why-vectors-are-important","title":"Why Vectors Are Important","text":"<p>Vectors allow models to: - Process words as numbers, making it easier to apply mathematical operations (like calculating similarities or differences). - Capture context: A vector for the word \"bank\" in a financial context will be different from one in a riverbank context, allowing models to handle polysemy (words with multiple meanings).</p>"},{"location":"foundations/LLMs/#how-vectors-capture-word-context","title":"How Vectors Capture Word Context","text":""},{"location":"foundations/LLMs/#meaning-of-vectors-in-context","title":"Meaning of Vectors in Context","text":"<p>When we convert words into vectors (using embeddings), each word gets a numerical representation that captures its meaning based on context. This is achieved by training the model on large amounts of text where it learns how words are used in different situations.</p> <ul> <li>Context matters: If the word \"orange\" is used in a sentence like \"I ate an orange,\" the model learns that \"orange\" refers to a fruit. If it\u2019s used in \"The sky is orange,\" the model learns that it refers to a color.</li> </ul>"},{"location":"foundations/LLMs/#how-context-is-captured","title":"How Context is Captured","text":"<p>Embeddings are generated using techniques like Word2Vec or GloVe. These methods assign words to vectors based on their co-occurrence with other words in different contexts.</p> <p>Example 1: Word2Vec (Skip-Gram Model)</p> <ul> <li>When the word \"orange\" is used in a sentence like \"I ate an orange,\" the model will learn that \"orange\" often appears near words like fruit, delicious, eat.</li> <li>When used in \"The sky is orange,\" it will often appear near words like color, sunset, sky.</li> </ul> <p>The model will generate different vectors for \"orange\" in these contexts because of the surrounding words. These vectors will reflect the specific context of the word in each case.</p> <p>Example 2: GloVe (Global Vectors for Word Representation)</p> <ul> <li>GloVe looks at the global context of words across an entire corpus. It learns that \"orange\" shares different co-occurrence statistics with words like fruit and color.</li> <li>The resulting vectors will still be close to each other, but they\u2019ll be distinct enough to represent different meanings in different contexts.</li> </ul>"},{"location":"foundations/LLMs/#dimensionality-and-contextual-representation","title":"Dimensionality and Contextual Representation","text":"<p>Each vector typically has many dimensions (e.g., 300-dimensional). Each dimension doesn\u2019t directly correspond to a specific meaning like \"sweetness\" or \"color,\" but rather represents latent features learned from data. These features emerge from how words relate to other words in sentences.</p> <p>For Example: - Context 1: \"I ate an orange\" \u2013 The vector might emphasize features related to edible, fruit, and taste. - Context 2: \"The sunset was orange\" \u2013 The vector might emphasize features related to color, sky, and nature.</p>"},{"location":"foundations/LLMs/#word-sense-disambiguation-wsd","title":"Word Sense Disambiguation (WSD)","text":"<p>Models like BERT or GPT are designed to handle this. They consider the full sentence (or even larger context) to adjust the vector of a word dynamically. This process is called contextual embedding, where the same word might have slightly different vector representations depending on its usage.</p>"},{"location":"foundations/LLMs/#why-vectors-capture-context","title":"Why Vectors Capture Context","text":"<p>By using large corpora of text, embeddings capture the statistical relationship between words in various contexts. This allows models to differentiate meanings like: - \"Orange\" as a fruit when surrounded by words like \"eat,\" \"juice,\" and \"sweet.\" - \"Orange\" as a color when surrounded by words like \"sky,\" \"sunset,\" and \"bright.\"</p> <p>Thus, vectors represent both the general meaning of the word and its specific meaning in context.</p>"},{"location":"foundations/LLMs/#tokenization-embeddings-and-transformers","title":"Tokenization, Embeddings, and Transformers","text":""},{"location":"foundations/LLMs/#tokenization","title":"Tokenization","text":"<p>Tokenization is the process of breaking down text into smaller pieces, such as words, subwords, or characters. These tokens are then fed into models for processing.</p> <ul> <li> <p>Why We Need It: Tokenization allows the model to handle text in manageable units. It\u2019s necessary because the model needs a consistent format to understand and process varying-length input.</p> </li> <li> <p>Example: \"I love AI\" becomes <code>['I', 'love', 'AI']</code>.</p> </li> </ul>"},{"location":"foundations/LLMs/#embeddings","title":"Embeddings","text":"<p>Embeddings are dense vector representations of tokens. Each token is mapped to a vector of numbers that capture its meaning based on context.</p> <ul> <li> <p>Why We Need It: Embeddings allow words to be represented in a way that preserves their semantic meaning. Unlike traditional one-hot encoding, which only shows whether a word exists or not, embeddings capture context and relationships between words.</p> </li> <li> <p>Word Embedding Example: The word \"cat\" might be represented as <code>[0.1, 0.2, 0.3, ...]</code> in a multi-dimensional space.</p> </li> </ul>"},{"location":"foundations/LLMs/#transformers","title":"Transformers","text":"<p>Transformers are a type of neural network architecture that processes input data in parallel rather than sequentially, making them highly efficient. They use self-attention mechanisms to focus on different parts of the input sequence for better context understanding.</p> <ul> <li> <p>Why We Need It:  Transformers are crucial because they handle long-range dependencies in text and process data much faster than older models like RNNs. Self-attention helps the model focus on relevant parts of the input sequence, even if they are far apart in the text.</p> </li> <li> <p>Key Concepts:</p> <ul> <li>Self-Attention: Allows the model to consider all parts of the input sequence at once, making it more efficient for tasks requiring context from multiple parts of the text.</li> <li>Positional Encoding: Adds information about the order of tokens, ensuring the model understands the sequence of the input.</li> </ul> </li> <li> <p>Popular Transformers:</p> <ul> <li>GPT: Focuses on autoregressive text generation.</li> <li>BERT: Focuses on bidirectional context understanding.</li> </ul> </li> </ul>"},{"location":"foundations/intro/","title":"Introduction","text":""},{"location":"foundations/intro/#generative-ai","title":"Generative AI","text":"<p>Generative AI is a type of artificial intelligence that can create new content such as text, images, music, or code by learning patterns from existing data.</p> <p>Examples</p> <ul> <li>ChatGPT \u2013 generates human-like text.</li> <li>DALL\u00b7E \u2013 generates images from text.</li> <li>GitHub Copilot \u2013 suggests and generates code.</li> </ul>"},{"location":"foundations/intro/#insight","title":"Insight","text":"<p>Traditional AI focuses on tasks like classification and prediction. Generative AI is different\u2014it creates new data, which opens up creative and automation possibilities.</p>"},{"location":"foundations/intro/#types-of-generative-models","title":"Types of Generative Models","text":"<p>Examples</p> <ul> <li>GPT (Generative Pretrained Transformer) \u2013 Text generation</li> <li>DALL\u00b7E / Stable Diffusion \u2013 Image generation</li> <li>StyleGAN \u2013 Face and image generation</li> <li>VAE (Variational Autoencoder) \u2013 Image compression + generation</li> <li>RNN / LSTM \u2013 Older models for text and music generation</li> </ul>"},{"location":"foundations/intro/#insight_1","title":"Insight","text":"<p>Each model has its strengths: - Transformers (e.g., GPT) are great for language and sequential data. - GANs are excellent for generating realistic images. - VAEs are used for controlled, smooth variation in generated data.</p>"},{"location":"foundations/intro/#connection","title":"Connection","text":"<p>As a dev, knowing the types helps you choose: - Use GPT-like models for chatbots, code generation. - Use GANs/VAEs for image-related tasks. - Use diffusion models for high-quality, customizable image generation.</p>"}]}